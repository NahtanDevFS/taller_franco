name: "Backup Database (Full & Vanilla)"

on:
  schedule:
    # Se ejecuta todos los días a las 03:00 AM UTC
    - cron: "0 3 * * *"
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    name: Backup and Upload

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install PostgreSQL 17 Client
        run: |
          sudo apt-get install -y lsb-release curl
          sudo install -d /usr/share/postgresql-common/pgdg
          sudo curl -o /usr/share/postgresql-common/pgdg/apt.postgresql.org.asc --fail https://www.postgresql.org/media/keys/ACCC4CF8.asc
          sudo sh -c 'echo "deb [signed-by=/usr/share/postgresql-common/pgdg/apt.postgresql.org.asc] https://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17

      - name: Install Rclone
        run: |
          sudo -v ; curl https://rclone.org/install.sh | sudo bash

      - name: Create Backups
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_DB_URL }}
        run: |
          set -o pipefail

          # Definir fecha para ambos archivos
          DATE_TAG=$(date +'%Y-%m-%d_%H-%M')
          FILE_FULL="taller_franco_FULL_$DATE_TAG.sql.gz"
          FILE_VANILLA="taller_franco_PUBLIC_$DATE_TAG.sql.gz"

          echo "--- Generando Backup 1: COMPLETO (Supabase Native) ---"
          # Este incluye todo: auth, storage, extensions, triggers, etc.
          # Ideal para restaurar en otro proyecto de Supabase.
          /usr/lib/postgresql/17/bin/pg_dump "$DATABASE_URL" \
            --clean --if-exists --quote-all-identifiers \
            --no-owner --no-privileges --encoding=UTF8 \
            | gzip > "$FILE_FULL"

          echo "Backup Full creado: $(ls -lh $FILE_FULL | awk '{print $5}')"

          echo "--- Generando Backup 2: VANILLA (Solo Public / Portátil) ---"
          # Este es para migrar a AWS RDS, Docker local, DigitalOcean, etc.
          # 1. -n public: Solo exporta tu esquema, ignora la basura de supabase.
          # 2. sed: Borra las llaves foráneas que apuntan a auth.users (porque en un postgres limpio no existen).
          # 3. sed: Borra políticas RLS que dependen de roles de supabase.

          /usr/lib/postgresql/17/bin/pg_dump "$DATABASE_URL" \
            --clean --if-exists --quote-all-identifiers \
            --no-owner --no-privileges --encoding=UTF8 \
            -n public \
            | sed -E '/REFERENCES "auth"."users"/d' \
            | sed -E '/REFERENCES auth.users/d' \
            | gzip > "$FILE_VANILLA"

          echo "Backup Vanilla creado: $(ls -lh $FILE_VANILLA | awk '{print $5}')"

          #exportar nombres a variables de entorno
          echo "FILE_FULL=$FILE_FULL" >> $GITHUB_ENV
          echo "FILE_VANILLA=$FILE_VANILLA" >> $GITHUB_ENV

      - name: Configure Rclone
        env:
          RCLONE_CONF_CONTENT: ${{ secrets.GDRIVE_RCLONE_CONF }}
        run: |
          mkdir -p ~/.config/rclone
          echo "$RCLONE_CONF_CONTENT" > ~/.config/rclone/rclone.conf

      - name: Upload to Google Drive
        run: |
          # Subimos ambos archivos
          rclone copy "$FILE_FULL" gdrive:backups_db/
          rclone copy "$FILE_VANILLA" gdrive:backups_db/

          echo "Ambos backups subidos exitosamente a Google Drive"

      - name: Rotate Backups
        run: |
          # Borra backups antiguos (>30 días)
          rclone delete gdrive:backups_db/ --min-age 30d
